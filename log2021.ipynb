{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logbook 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monday, January 4\n",
    "I was very bad at keeping up with this during the winter braek even though i still did some work - no sense in trying fruitlessly to cath up now! <br>\n",
    "\n",
    "Brief summary: did correlation, MLS, and variance in winter month comparison of HRDPS and CanRCM4 datasets for 2016,2018,2017,2019 and found that the two datasets correlate SO poorly that it really doesn't make sense to try to downscale using a NN. Worked for a while on making and exporting the preprocessed HRDPS data in another file that would just be run once and never be touched again. Will do the same for PCs. <br>\n",
    "\n",
    "In MOAD meeting today talked about the lack of correlation within the four years that I looked at - was suggested that 2016/2017 winter may have been super weird which is why the model couldn't capture it, but no good reason why the other years look so shit too. SUggested that I look into a larger range of years of data (this will be possible with code that Doug fixed up). <br>\n",
    "\n",
    "Really informative meeting with Doug on what/why he changed to my LoadFiles notebook. Suggested that the removal of the leap day be done after PCA is performed as this dataset will be smaller and easier to work with. Want to load more years of data than we have rn (based on discussion in MOAD meeting) - use the code he has now to make a netcdf file of the HRDPS data with current naming convention (2015 onwards) and a sepratre netcdf for old naming convention (b4 2015) and then concatenate them in the PCA file. <br>\n",
    "Briefly went over how parrallel processing works with dask. Really helpful analogy with clerics counting the number of times a word is used in the bible. The number of clerics (and therefor the number of portions the bible is split into) is the number of processes going on, while the number of words that a cleric can keep track of at once is the number of threads each - this is a simple way of explaining how  computer can 'multitask' using dask. <br>\n",
    "&emsp; NOTE: salish has 16 cores (which looks like 32 when doing what you were (io memory stuff) because there are two threads for each core) so you cannot split your work between more than 32 clerics (less if there is any other work being done on Salish and 16 max if its being used mostly for computing).<br>\n",
    "\n",
    "Some new fun top tricks:<br>\n",
    "&emsp; u -> userID : to see userspecific processes <br>\n",
    "&emsp;&emsp; V : for tree of this users processes <br>\n",
    "&emsp; 1 : to see what all 32 cores are up to<br>\n",
    "&emsp;&emsp; us column = computing memory being used<br>\n",
    "&emsp;&emsp; sy = io memory being used<br>\n",
    "&emsp;&emsp; ni = priority (more posstive is low priority, more negative is high priority, set as 0 automatically)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuesday, January 5\n",
    "Ran and saved HRDPS netCDF files from Sep 2014 to present. Old file types are VERY funky. Some dates have time values from other dates, and the hourly time values within those dates are sometimes not in order. Seems to happen too often to be as simple as me fixing those dates (and still have time to do analysis for the presentation) so just going to do 2014 to present analysis. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wednesday, January 6\n",
    "Lots of progress on downscaling project. Formally moved on from doing downcalling with older HRDPS data. Completed PCA file and exported all the necessary PCA values, time, and lat and lon. <br>\n",
    "Began working on converting larger analysis over to using these exported numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friday, January 8\n",
    "Productive and informative meeting with Ben this morning on PCA analysis. Learned the proper termanology in our field for some PCA stuff: <br>\n",
    "&emsp;EOF = eigenvectors<br>\n",
    "&emsp;Eigenvalues = fracVar<br>\n",
    "&emsp;Principle Loadings = PCs<br>\n",
    "Also gave me the suggestions to create histograms to show the statistics of what's different between the models.<br>\n",
    "As an aside showed me a file that shows how to make his pretty plot with the outline of the Salish Sea, can be found at this link:https://github.com/SalishSeaCast/analysis-ben/blob/master/notebooks/maps_cartopy.ipynb <br>\n",
    "Also gave me a good book reference for PCA in oceanography: *\"Principle Component Anlysis in Meteorology and Oceanography\" Preisendorfer 1968*<br>\n",
    "\n",
    "Meeting with Susan, she wants me to compare 2014 of climate model to 2014 of SandHeads data. Also suggested to look at switches between high and low and amount of high versus low days in histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saturday, January 9\n",
    "Worked a ton today on completing the 're-vamp' of the SLP file, to amke it compatible with the new PCA and LoadFiles notebooks. Began the same turnover for the wind file. I found a couple errors in the PCA file that lead to the V-wind to be overwritten with the SLP data, so had to fix that before continuing. Wasted a lot of time on trying to combine the first two modes of the wind PCA results upon Ben's suggestion - i should have asked him how exactly he meant to do this (not sure if weighted sum or just regular sum??)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sunday, January 10\n",
    "Thought more about whether or not (and how) to combine the first two modes of the PCA results or jus tot leave them as is and analyse sepertely and i decided to keep them seperate since a) i don't actually know for sure how to combine them correctly (again, ask Ben about this since he definitely eluded that it was quite simple) and b) the eigenvectors of these modes between datasets look very simimilar, to makes resonble sense to comare them directly. <br>\n",
    "Worked the rest of the day on finalising the conversion of the wind file to be compatible with the PCA and LoadFiles notebooks. Added histograms for the whole year and seperate winter of distribution of normalised wind speed and SLP. Made count plot of amount of switches in wind direction and SLP high-lows. <br>\n",
    "Made notebook and plots for comparing winds at one datapoint of the CANRCM4 model to the SandHeads data - this turned out fine but i did it reasonably late at night and i FORGOT TO ADD THE CSV FILES THAT I MADE AND USED FOR THIS NOTEBOOK TO THE .GITIGNORE AND NOW I CAN'T PUSH TO GIT AND NEED TO FIGURE OUT THAT FORGET THING THAT IS APPRENTLY RATHER COMPLICATED UGHHHHHH - maybe i ask Doug for a meeting some time after the presentation to do this together. Just can't upload anyting to git until then... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monday, January 11\n",
    "MOAD meeting in the morning we met the new coop students, i have a prescribed coffee data with Aline. <br>\n",
    "SUggestion to look into where wind is being measured as comparison to SandHeads looks really odd - checked though and measured at 'near surface'.<br>\n",
    "\n",
    "Really interesting stuff from Tereza and Elise stuff today in MOAD meeting: <br>\n",
    "Amount of biomass is small in the JDF (but productivity high) - but out model and others (look at Masson and Pena) show very high biomass. <br>\n",
    "&emsp; - the JDF is a low stratitificaiton region, therefore at the surface chlorophyll is lower but it persists further down than in stratitifed regions <br>\n",
    "&emsp; - so has an overall high biomass signal<br>\n",
    "IMPORTANT: In the model the JDF signal is later in the year than the SoG BUT we usually go out for measurements when the SoG is blooming, therefore may be measuring at times that are biased for low productivity<br>\n",
    "&emsp; - since we don't have observations for the JDF bloom time we can't diffinitively say the model is wrong<br>\n",
    "&emsp; - furthermore, in the model we can't change the impact of light enough (which is said to be why there is lower productivity in the JDF) to get model to match the limited observations we have for both the JDF and SoG<br>\n",
    "\n",
    "This leads us to the question of why does the JDF have a summer bloom instead of a spring bloom?<br>\n",
    "&emsp; - deeper mixing, brings more nutrients to the surface<br>\n",
    "&emsp; - mid-summer incoming solar radiation is maximised, typically deep mixing inhibits the bloom but light can get deeper in mid-summer<br>\n",
    "&emsp; - flow of phytoplankton from the SoG<br>\n",
    "NOTE: super high productivity years may corresnpond to blob years. <br>\n",
    "\n",
    "TA meeting in the afternoon, now rescheduled to Thursdays. <br>\n",
    "\n",
    "Worked on presentation slides. Finished first draft of all slides, need to work on script tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuesday, January 12\n",
    "Worked more on script for presentation and fiddled with slides. Did not finish script before meeting with Susan but did got more suggestions from her on what to include and how to format my slides (so i'm glad i didn't finalize everything first). Other than just basic formating:<br>\n",
    "&emsp;Wants me to add 0 lower limit to varience and major changes graphs so that we aren't 'tricked' into thinking that they are more different then &emsp;they are. <br>\n",
    "&emsp; - show variance formula <br>\n",
    "&emsp;Â - look at summer versus winter variance <br>\n",
    "&emsp; - make sure you are de-meaning the data before analysis it <br>\n",
    "Decided to re-define major changes as diffrence in 0.3 between two days instead of a -ve to +ve change<br>\n",
    "\n",
    "First lectures in methods class - pretty interesting but won't be difficult until afer reading week. Start brainsotrming the type of field measurments you'd like to take/analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wednesday, January 13\n",
    "Another meeting with Susan on presentation and added and edited a few other things in the presentaiton. Finished scirpt afterwords and practiced a bit. <br>\n",
    "\n",
    "First class in EOSC 579, going over internal waves first (which you learned a bit about in 471)- just Cuiyi and I so review notes before class because RICK adores asking a ton of questions to us that I apparently remember none of.<br>\n",
    "\n",
    "First class in estruary course - prof is SUPER frednly, spent half the time introducing ourselves. Other half brief intro to Estruaries and density. Didn;t quite get to Knudsen relationship. Finish assignment 1 by next class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thursday, January 14\n",
    "Presented my analysis thus far on the CanRCM4 downscaling infront of the group and members of the DFO - it went adequately. Raised a pretty long discussion afterwords about what to do next. They are actually quite happy with how well the CanRCM4 could capture the variance. How well you need the downscaling to match every storm depends on what you are using this downscaled information for, ex. need to match storms for phytoplankton bloom timing, only needs to match magnitude and varaince for overall circulation study. <br>\n",
    "\n",
    "In EOSC 573 went over what physical oceanographers measure and reasonable ranges of values we can expect to see in the ocean: -2 - 40 deg C for temperature, 0 - 45 g/kg for salinity, and 998 - 1050 kg/m3 for density <br>\n",
    "\n",
    "First of weekly coffee hangs with group members with Aline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friday, January 15\n",
    "In meeting with Susan we discussed the next steps for me for the downscaling project. Wants to make sure that I am starting to turn my focus onto the JDF. So - will continue the downscaling assessment but will use real wind data from a measurement location in the JDF for comparison with HRDOS data. This way although I am continuing with this project, I will at least be getting more used to how things work in the JDF. <br>\n",
    "PLAN: process a year of station data in JDF (maybe port angeles?) and process the same way as you did the HRDPS data. What is the variance in winter? How does the HRDOS compare? How many EOFs do we need to get 98% of the variance? Do comaprison of wind, wind2 (related to momentum transfer, drag), wind^3 (related to mixing driven by wind). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saturday, January 16\n",
    "Did covid and chemical safety training for EOSC 573. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sunday, January 17\n",
    "Assignment one for CIVL 547 on the equaiton of state. Mostly coded in python. <br>\n",
    "\n",
    "Began reading recomended biological oceanography paper from Tereza on the bloom timing, climactic conditons that bring theseblooms on, and phytoplankton composition of blooms in the NSoG between 2015 and 2018 - *Phytoplankton Composition and Environmental Drivers in the Northern Strait of Georgia (Salish Sea), British Columbia, Canada*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monday, January 18\n",
    "MOAD meeting in the morning, showed those who did not attend my presentation some of the final results of what I presented. Explained that I am going to look more specifically at the JDF now. <br>\n",
    "\n",
    "Reached out to Doug about fixing my github push problem - he will look into it later this week and if he can figure it out will schedule a meeting with me to show me how to fix it. <br>\n",
    "\n",
    "Productive meeting with Tereza on Carbon in the JDF. Sent me an email with some good reasdings fo rme to look at on phytoplankton in the JDF. Exaplined some stuff about her paper and will send me a less 'bare-bones' version that will explain a few things in more depth. Some useful stuff i learned:<br>\n",
    "&emsp; - diatoms and flagelates are the two most important types of phytoplankton in the Salish Sea <br>\n",
    "&emsp; - We measure TA and DIC but in terms of impacts people care about pH, the partial pressure of CO2, and aragonite <br>\n",
    "&emsp; - Can use mocsy (by James Orr) as a good tool in python to do these Ta & DIC conversions to useful things<br>\n",
    "Stressed that we should keep open communication with eachother to make sure there is no overlapp in our research. <br>\n",
    "\n",
    "Formatted and submitted CIVL 547 assignemnt 1 <br>\n",
    "\n",
    "Finished readings on lagrangian vs. eularian vs. tracer perspective by SW Stevens - satrted but still must finish summary writeup. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuesday, January 19\n",
    "Methods course asked Rich about using drifters for my field study. Seemed open to it as long as my proposal is good!<br>\n",
    "\n",
    "Read through the many meeting minutes sent to me from ENVR 400 team - meeting with them went well and gave them some ideas for what their figures could look like. I think they are on the right track and are more realistic now about assigning some sort of economic measurement in order to make their thing usable. Introduced the idea of a \"living document.\" <br>\n",
    "\n",
    "Meeting with Susan, doesn't seem to be worried about overlap with Tereza's work. I am moreso using nitrate and DIC as useful tracers for where the JDF water is coming from and how it is moving whereas Tereza is more explicitely focusing on the transport of carbon. <br>\n",
    "\n",
    "Found good hourly data at two cites on the JDF at Race Rocks and Sheringham Point. DOwnloaded hourly data form these cites back to 2007, still must be processed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wednesday, January 20\n",
    "Conceptually went over assignemnt 1 in CIVL 547. All must re-hand-in assignment 1 and do assignment 2 for next class. Vero reached out to me to work on assignments together! My plot for temperature of amx density with salinity variation is wrong right now - figure out why before working with Vero. <br>\n",
    "\n",
    "Began processing Race Rocks data - figuring out how to do similar processing as i did in the load-files doc but with pandas dataframes instead of netCDF. <br>\n",
    "\n",
    "Re-read EOSC 471 notes on internal waves and re-read all EOSC 512 summary notes to be better prepared for EOSC 579 lecture. Was actually able to answer questions today!! <br>\n",
    "Learned about the behaviour of internal waves between a bottom and surface boundary and the effect of a bumpy bottom. I still don't fully understand what an internal wave mode versus an internal wave ray is - try to figure out before next class. <br>\n",
    "\n",
    "Rich brought up in EOSC 579 lecture that just using drifters alone for methods course would be pretty boring. Suggested combining them with CTD data to see if the flow regimes that the CTD results infer are confirmed or not by the drifters. Need to let him know next week or so if i want to use the drifters as they will need to built (not hard or expensive just takes time) before we go out. <br>\n",
    "Suggested maybe looking at very fast outflow jet along north shore from first narrows. Take CS across across the outflow jet in the top 10 m, drop drifters and pick them up just a few minutes later. <br>\n",
    "Rich will be posting resources for understanding the flow regimes in Burrard inlet soon, so look at that to decide what kind of flow you're interested in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thursday, January 21\n",
    "In methods course learned about biological oceanography field work. For the most part i did not find this that useful BUT learned a bit more detail on the phytoplankton that Tereza highlighted as important in the SoG. <br>\n",
    "&emsp; - Diatoms: opaline skeletal structure, 5000 species that fit into 2 catergories (centric or pennate) based on how they connect together to form long chains<br>\n",
    "&emsp; - Dinoflagellates: 1800 species, mixotrophs, cause of red tides <br>\n",
    "&emsp; - Nanoflagellates: small (< 10 um), mixotrophs, mobile<br>\n",
    "Also learned what is considered ample (2000 uE m-2 s-1) and low (100 uE m-2 s-1) light. Some phytoplankton die right at the surface due to over exposure to light, so the chlorophyll max is typically a little below surface. <br>\n",
    "\n",
    "TA meeting in the afternoon, not much to go over. One of Michaels groups is having problems. Relfection 4 is due this Friday so try to mark over the weekend while you're still not busy. <br>\n",
    "\n",
    "Started working on 'fixed' assignment 1 for CIVL course + first go on assignemnt 2. Still getting the wrong relationship for my temperature of maximum density versus salinity plot and i am not sure why. Hopefully Vero can help tomorrow. <br>\n",
    "Think that i got question 5 and 6 right for assignment 1 (I think people in class are wayyy over complicating it) and assignemnt 2 i think i'm done as well, although i made an assumption with regards to density that I should run by Vero tomorrow as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friday, January 22\n",
    "Worked on RaceRocks and Sheringham analysis in the morning. Racerocks has fewer gaps in the data so I am thinking of focusing on that. Also it is on an island so has higher winds than the coastal values of Sheringham which I think are more useful for what I am attempting. <br>\n",
    "\n",
    "Met with Vero at 11 to go over our work so far. She is not very comfortable with python so could not help with problem in my code but we talked over our assumptions and process together to make sure that we are on the right track. She gave me the idea to use the density relationships we derove in assignment 1 instead of making assumptions about them for assignemnt 2 (still must assume a temperature fo the water but I think this will be more accurate). We sent eachother our script/sheet and will try to help eachother out. Excited to have a friend in this class already to work with!<br>\n",
    "\n",
    "Meeting with Susan she explained to me why the channel between Vancouver Island and Lasqueti Island was rejected as the path where trasport occurs in Sam Steven's paper even though that's what the Lagrangian modelling said was happening. The model does not have the high resolution bathymetry information in it (since there is no way right now to put this much detail in) so based on the low-resolution bathymetry it has, it thinks that this channel is a good choice (since it it wide) BUT in reality this channel is super shallow so it is unlikely that it is the main pathway. Hypothesied by Rich (but not yet confirmed) that a thinner but much deeper channel to the east is the main pathway. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sunday, January 24\n",
    "Worked on CIVL assignment 1 again, and after a few days of not looking at it noticed that I had forgot to put -ve's in front of two of the b-coefficents and this is why my relationship was off! Everyhting working now so i was able to make all of the plots look pretty and put a word doc togther to sumit both assignment 1 and 2. <br>\n",
    "\n",
    "Trimmed the HRDPS data to only look at the point closest to RaceRocks. I realised after this though that the HRDPS data I am working with right now is the daily average. This is a step I took to make it match the CanRCM4 data but doesn't make sense to use for comparing to the RaceRocks data which is hourly. Must go back to old LoadFiles and PCA notebooks and redo them for hourly data processing. <br>\n",
    "\n",
    "Got over half-way through grading ENVR 400 reflection 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monday, January 25\n",
    "Finished marking ENVR 400 reflection 4 this morning. <br>\n",
    "\n",
    "In MOAD meeting Susan let me know about a meeting she had with the DFO on the donscaling project. A previous student from the DFO was part of the meeting (Alex Cannon) who works in statistical machine learning in this field and explained a way to match the models using their statistics instead of their storms. Seems really cool, I look forward to hearing more about it. <br>\n",
    "Through this conversation i also FINALLY figured out what Susan wants me to do rn. Basically reconstruct the HRDPS data using your PCA results (the hourly ones) and see how well the reconstructed point closest to Race Rocks matches Race Rocks. Interested to see if there is a good match and if there is, how many modes it takes to get this good match. <br>\n",
    "\n",
    "Worked on redoing the LoadFiles and PCA analysis on hourly HRDPS data. Was able to export a netCDF successfully using a new version of LoadFiles but still need to complete the PCA. I believe that my re-worked PCA file will run without a problem but need to wait until this evenning as processing years of hourly data takes up a lot more space than processing the daily data and I think it would be best to run it on the server when no one else is on salish. Note that I am now also doing the conversion to wind speed and direction (instead of U and V) in this file. Remeber to export the seasonal trand values that you subtract so that you can get back to the full values later. <br>\n",
    "\n",
    "In PO seminar Rick gave an interesting presentation on his drifters and why they may ground so much in the SoG but not in the St.Lawrence. Drifters staying much closer to shore than expected (seeing log-layer relationship in theit distnace from shore relationship). Found rn that Stokes drift and tides are not the reason. <br>\n",
    "Ask him to talk in class about the internal waves in the South China Sea around the Dongsha Atoll. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuesday, January 26\n",
    "Run overnight on hourly version of PCA did not work. Tried again this morning with commenting out all pressure parts and running that (then will comment out all direction parts and do that too) and i think that will work. Doug has to run a big thing though so need to wait a couple days. <br>\n",
    "Susan suggested that i just start with making racerocks daily and comapring that way. Didn't get as far in that new process as I would like to have but seems very doable. Having some problems with my HRDPS data not being the right length (off by about 300 days) and I'm not sure why this is happening since I am using almost the same process as I did in the big wind analysis file. Look into this tomorrow. <br>\n",
    "\n",
    "Methods lecture on biological oceanography. Expanded into zooplankton. Nothing too exciting to note. <br>\n",
    "\n",
    "Started on pre-proposal file for methods project. Want to analysis the jet along the north shore of English Bay using both drifters and CTD, but I am not actually sure why this research is useful in any way so far. Potentially can use it to determine the accuracy of SalishSeaCast FVCOM results in that area but I am not sure if that is useful. Thus idea came from cool SalishSeaCast graphics of English Bay at https://salishsea.eos.ubc.ca/fvcom/results/nowcast-r12/publish/22jan21 <br>\n",
    "Ask Rich to speak about this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wednesday, January 27\n",
    "In estuary course learned that he wanted us to use equations from his paper not from this figure from the same picture, so must redo assignment sections with more precise determination. Met with vero for a bit after class to go over this.<br>\n",
    "Went over momentum equations in class and for estuaries (instad of more general ones covered in GFD) look a lot more different than I thought they would. Go over this again b4 next class (must solve for assignment 3 anyways). <br>\n",
    "\n",
    "Met with Elise for coffee hang, t'was nice. <br>\n",
    "\n",
    "Redid code for assignment 2 in estuaries class using Guha & Lawrence JPO 2013. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thursday, January 28\n",
    "Re-wrote and formatted assignment 2 for CIVL. <br>\n",
    "\n",
    "Made reconstruction for downscaling project to compare to Racerocks. Ready to show Susan some stuff and get her comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friday, January 29\n",
    "Re-read Thompson 1981 section on Burrard inlet in an effort to get a better idea of what i want to address in my methods project. I spoke about this later with Susan and she suggested that my 'why' could be looking into why oil spills in the inlet effec the north shore more than the south. Also very difficult for sailors to navigate that area. Additionally still cool and interesting to compare it to VHFR FVCOM results. Will work on the-preproposal this weekend toget it to Rich by monday. <br>\n",
    "\n",
    "Call with Susan, in addition to talking about my methods project, was productive. Learned that my reconstruction of the wind direction my not be wrong.. oceanographer and atmospheric scientists measure winds oppositely so its just a perspective thing - flip the recerocks values. For interest, plot the raw hrdps data versus the racerocks data to see how well that matches up before comparing reconstruction. <br>\n",
    "Susan thinking that since wind direction modes dont match up as well (as expected) since direction is the hardest to get accurately between models that she may combine the U and V wind speeds into one dataset with just twice the spatial area and do my analysis on that. She showed me some of the stats taht she's been doing on the data, and once you normalise both datasets by their variances they show really similar behaviour. <br>\n",
    "Susan to send my the ocean parcels (a simpler version of arianne) code to start playing around with. <br>\n",
    "\n",
    "In EOSC 579 i took up about half the lecture asking Rich the difference between an internal wave mode and an internal wave ray. Extremely helpful but i didn't write notes since i wanted to take as much in as possible and stay alert. Re-watch video and jot down some notes for reference in the future. <br>\n",
    "\n",
    "Worked on CIVL asssignment 2 and was able to complete what i think he wants for question 1 (derivation of the along strait velocity) much more easily than I thought I would be able to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sunday, January 31\n",
    "Read the relevant section of MacCready & Geyer (2010) for assignment 3 question 2 in CIVL. Met with Vero to talk about the assignment. We arrived at the same answer slightly differently for question 1 and both agree that for question 2 we just need to write MacCready & Geyer (2010) derivation of the salt flux equation in our own words. <br>\n",
    "\n",
    "Wrote up pre-proposal for moethods course to send to Rich tomorrow morning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monday, February 1\n",
    "Implemented suggested extra info for Rich into my pre-proposal (added tide tables to show more precisely when the edd tide occurs). <br>\n",
    "\n",
    "Flipped wind data and added plot of original HRDPS data into data analysis code. Wind data in HRDPS doesn't like to blow west as much as the Race Rocks data and doesn't reach as high of magnitudes. Ben showed me his wind rose for race rocks during the MOAD meeting and it agrees with this analysis. Look at his code more and see what you can learn from it (even if it is just making your code more neet). <br>\n",
    "\n",
    "Wrote up question 2 for CIVL assignemnt - I attempted to write the steps and assumption in my own words but summarising a summary just becomes very paraphrasy. Look into the other papers referenced in this review - in particular MacCready 1999 and 2004. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuesday, February 2\n",
    "Read MacCready 2004 and edited CIVL assignment 3 question 2 to have info from it. Handed in assignment. <br>\n",
    "\n",
    "Meeting with Susan, she suggested looking at sites on american side of JDF to comapre to HRDPS data. Look at POint Angeles, Neah Bay (doesn't hurt to do comparison with sharingham as well) and compare to HRDPS data from that area. This is relevent to your thesis as you will have a disucussion on the accuracy of the input into the model, wind being one of them. <br>\n",
    "She sent you ocean parcels code this morning, look into it tomorrow and thursday. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monday, February 8\n",
    "VERY behind on this and no point catching up now, jsut gotta get good at doing this every day again. <br>\n",
    "Plotted Sheringham, Neah Bay, and Point Atkinson against HRDPS data the HRDPS data looks like a good match with the Neah Bay data - this is to be expected though since Neah Bay is closer to the open ocean and HRDPS is better there. What we really care about it whether or nor HRDPS is good at modelling the inland stuff but Point Atkinson has too much bad data to chaeck this. Don't know if there are any other good spots to check but can look into this further. <br>\n",
    "\n",
    "Retyped assignemnt 3 for CIVL and handed that in. Did question 1 of assignment 4 which is basically just a redo of the harder stuff in assignment 2. Went over the rest of the assignment with Vero and we have no clue how to do question 2 or 3. Dr. Lawrence said that we only need question 1 for next class so that's fine for now, hopefully it becomes clearer later. <br>\n",
    "\n",
    "Started question 1 for EOSC 579 assignment 1 - think i got the derivation of sigma and w down. Little worried about question 1 b.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuesday, February 9\n",
    "Read over Ocean Parcels code and talked over with Susan. Chosen r value is just because its a nice size visually for the SoG, deg2m is just a degrees to m conversion for the region based on our lat and lon. Susan says to focus on the OceanParcels stuff for now - pretty happy about this, i had basically ceased to be excited about the HRDPS stuff and didn;t really see where what i was doing was going. <br>\n",
    "\n",
    "Got deeper into assignemnt 1 for EOSC 579 and realised that i had made some arithmetic errors in my sigma derivation so fixed that. Plotted w contours and quiver plot at different times and did the calc (and plotted) for the thrid mode. Still struggling with 'b' but was able (i think) to answer 'c'. FOr this part i want to rewatch the part of the earlier lecture on what it looks like for difference sigma values if N>f bc i'm a little confsed about my results based on how i worte my notes. <br>\n",
    "\n",
    "First ENVR 400 lecture over zoom went OK - will no loger try to premake breakout groups just gonna let the students move between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wednesday, February 10\n",
    "Well, the CIVL lecture was very informative - i was definietly interpreting question 2 and 3 of the assignment wrong. Adam Yang (a phd student of Dr. Lawrence's who took this course a few years ago) gave an overview of how he did it and used euquation 13 (using forward difference to solve) and then 14 and 15 from Guha and Lawrence to solve question 2 and 3 so hopefully I can figure that out. Went over with Vero after class and neither of us could figure it out lol but hoprefully when i have more time it becomes more clear. <br>\n",
    "\n",
    "Worked most of the day on my proposal for methods course field work. Main adjustments were adding a deeper explanation to my 'why' section and a lot more detail to my 'where/how' section (geographic coordinates, spacing, how long i estimate things will take, etc.) hopefully its good enough now. Perhaps needs more reasoning as to why i chose a 30 m depth of profiles. <br>\n",
    "\n",
    "EOSC 579 lecture today i asked about the __ __ spectrums we learned last class since they confused me quite a bit - hoesntly Rich agreed that I should rewatch the lecture for more clarity but admitted that they're extremely confusing, he doesn't fully understand some of the steps taken (as they seem like big leaps and large assumptions) and i won't raelly ever be tested on this (in this course and beyond). <br>\n",
    "Rich asked if we'd rather learn about coastaly trapped waves or steady oean circulation for hte rest of the course and i said castlay trapped as it is closer ot my research subject, but i am maybe regretting this choice as ocean circulation sounds super interesting (and maybe easier?). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thursday, February 11\n",
    "Worked on making the ocean parcels code my own (for the JDF) but need to find the locaiton of the some of the files Susan calls in her file - VERY silly of me to not realised i needed to ask this quesiton when i met with her and asked other questions on tuesday. <br>\n",
    "\n",
    "Added to CIVL discord channel where Vannary posted some great resources for how to do the forward difference approximation - will try that tomorrow. <br>\n",
    "\n",
    "Uploaded LoadFiles notebook to python resources MOAD repo (did not write notes on this date but last week thursday was a python aply session and when no one had anything to present i kinda just went for it and showed the dask stuff the Doug had shown me to everyone!). <br>\n",
    "\n",
    "Chrome crashed quite regurlalry today - hopefully this problem does not continue. <br>\n",
    "\n",
    "Methods lecture was actually quite interesting today, chatted about nurtrient uptake (particuarly nitrogen) so could be relevant to your thesis. Write notes on these lecture slides on a later date. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friday, February 12\n",
    "Productive call with ben this morning - he informed me that i should go through the Salish sea read the docs before trying to run ocean parcels. That document will show me where to get access to the files that Susan calls in her code. He also hopes that by next week he will have a nice and easy to understand bare-bones ocean parcels code example in the python tools repo that will help me out. <br>\n",
    "\n",
    "Spent most of the rest of the day working on my CIVL 547 assignment 2. Call with Vero was nice, worked on forward difference approximation based on Vannary's resource and after a LOT of working on my algebra i got it to work! Made bare bones contour plots that i think are correct! Just got to make them look pretty and type up an explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saturday, February 13\n",
    "Made my contour plots look gorgeous! Not sure hw adam yang was able to satisfy a no slip contdition on the bottom boundary. This sounds right in theory BUT we used the same process and equations from the same paper (a paper that does not mention these boundary conditions). Very weird, i'm not sure what extra magid he did and no one in the discord chat seems to know either. Perhaps they'll get deeper into it and can help out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sunday, February 14\n",
    "Went on the boat today! Very fun stuff, did a ctd profile (with and without water samples), took water samples and seperated water for O2 measurement (added reagents that turn orange when they consume O2), chlorophyll, nutrients, and phytoplankton, did a light scan using an actually measuring thing (sunny side) and a secchi disk (dark side), did a phytoplankton and zooplankton tow. Very fun! Doing the exact same thing on Tuesday morning (I volunteered for an extra slot) so i'm sure i will be able to take in omre detailed info then, lol. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monday, February 15\n",
    "Finshed assignment 4 for CIVL 547 (quesiton 4 and 5, write up, and formatting). <br>\n",
    "\n",
    "Attempted question 2 for EOSC 579 in order to ahve some SLIGHTLY smarter things to try to ask Rich about it tomorrow - calcualted the phase and group speed for each wave but really not clear to me where this gets me in terms of wave behaviour. <br>\n",
    "\n",
    "Follwed the Salish Sea read the docs to setup the MEOPAR repo I need to run salish sea related things on my computer. Now i just need to figure out how to run chum remotely, as when i try to do it the same way to run Salish remotely it doesnt work! never easy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuesday, February 16\n",
    "Day two of training on the boat today! It was nicer weather out but the waves were high in Engligh Bay (and the boat small) so we needed to stay and do sampling in the protect water of False Creek. Three stations, two bottles each, one at 0 and one at 5 m (water was a total of 8-10 m deep). Defintiely felt very confident this time and sampling went more efficiently. <br>\n",
    "\n",
    "In the afternoon we did the measurement of our oxugen samples using the winkler method - automatic titration, if only we were allowed to use this in CHEM 1040! Apparently we had the best oxygen results of the week but still not good enough to be acceptable in an actual paper. <br>\n",
    "\n",
    "Prepared chlorophyll and nitrate samples to incubate overnight. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wednesday, February 17\n",
    "Analysed chlorophyll and nitrate samples in the morning. <br>\n",
    "\n",
    "CTD processing in the afternoon - mostly done on a seabird program that does all the preprocessing for you. Must do the rest of the analysis via code - Rich suggested matlab code (that i think there is a link for on the canvas site but i can't find?) but am going to try to do it on python. <br>\n",
    "\n",
    "Started microscope lab by looking at phytoplankton samples - i suck at analysing phytoplankton. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thursday, February 18\n",
    "Spent the morning analysing zooplankton and phytoplankton samples with some very weird math that was made to much more complicated than it was. Will redo when i do this on python because i don't trust our blacboard math. <br>\n",
    "\n",
    "Helped Rich get RBR and other field equipment ready for tomorrow. Had to add weights to the RBR because its REALLY weirdly designed and istn heavy enough to sink even though its meant to sink. Needed to add tape to rope for it too (as back up for magnet pully). Magnet pully has a little magnet that counts how much rope has gone through it - therefore if you reset it when the RBR is at the surface then it counts how deep you've gone. Setup start time for RBR to start tomorrow at 11:59 am."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friday, February 19\n",
    "In the field today! Helped Emily with her stuff from 8-11. Somewhat conerned about winds in the morning but decided to just go for it and see how many samples we could get before the winds got too bad but it actually really turned out! Almost no winds at all! Got 29 samples and we had only really hoped for 16!! Wowzers<br>\n",
    "SAW PORPOISES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saturday, February 20\n",
    "Caught up on a bit of work today! Typed up some of the data collected from this past week and fixed my CIVL547 assignment 4. <br>\n",
    "\n",
    "Created repo on github for EOSC573 field project analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sunday, February 21\n",
    "WELL tried to do more coding and data processing today. Tried to analyse CNV file (seabird CTD output) using seabird.cnv package but it did not work for whatever reason! and it always works apparently so there's no troubleshooting tips! WTF! ask about it in MOAD meeting tomorrow. <br>\n",
    "\n",
    "Tried to do more of OceanParcels code and hit road block in Susan's version of the code because idk the source of her SalishSea files. Tried Ben's version and getting really weird error - same source files as him for sure but something wrong in my anaconda setup????? <br>\n",
    "\n",
    "Did nutrients and oxygen analysis of data from last week. <br>\n",
    "\n",
    "Did math (i think correctly!) for EOSC 579 assignemnt 1 1.b). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monday, February 22\n",
    "Finished plotting and started typing up EOSC 579 assignment 1 question 1 - this is me avoiding doing question 2. Rich said the dew date was quite flexible so i inquired about this and he just extended this for everyone by a week. Found some videos that will hopefully be helpful for question 2. <br>\n",
    "\n",
    "Handed in assignemnt 4 for CIVL 547 and began working a bit on assignemnt 5. <br>\n",
    "\n",
    "Figured out how (theoretically) to fix my problem with Susan's Ocean Parcels code. Nemo path AND prefix function are not correct. Matt put the filed stright in his folder but i not only need to get to the correct folder (the Nemo path part, Susan provided this and will be an easy fix) but i also need to add the daily subfolder to the prefix function (less easy of a fix but doable). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuesday, February 23\n",
    "Finished plotting and typing up EOSC 579 assignemnt 1 question 1. <br>\n",
    "\n",
    "Finished first draft of code and writeup for assignment 5 CIVL 547. Seemed pretty simple! Hopefully i am not proved wrong. <br>\n",
    "\n",
    "Marked late reflections that came in for ENVR 400 and marked my team's figures assignment, with a lot of comments. <br>\n",
    "\n",
    "Meeting with Susan, told her about weird my problem with Ben's code and she suggested speaking to him before I speak to Doug. Ack. Re-run this first and come up with a more intelligent way to word the question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
