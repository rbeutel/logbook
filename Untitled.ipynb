{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logbook 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monday, January 4\n",
    "I was very bad at keeping up with this during the winter braek even though i still did some work - no sense in trying fruitlessly to cath up now! <br>\n",
    "\n",
    "Brief summary: did correlation, MLS, and variance in winter month comparison of HRDPS and CanRCM4 datasets for 2016,2018,2017,2019 and found that the two datasets correlate SO poorly that it really doesn't make sense to try to downscale using a NN. Worked for a while on making and exporting the preprocessed HRDPS data in another file that would just be run once and never be touched again. Will do the same for PCs. <br>\n",
    "\n",
    "In MOAD meeting today talked about the lack of correlation within the four years that I looked at - was suggested that 2016/2017 winter may have been super weird which is why the model couldn't capture it, but no good reason why the other years look so shit too. SUggested that I look into a larger range of years of data (this will be possible with code that Doug fixed up). <br>\n",
    "\n",
    "Really informative meeting with Doug on what/why he changed to my LoadFiles notebook. Suggested that the removal of the leap day be done after PCA is performed as this dataset will be smaller and easier to work with. Want to load more years of data than we have rn (based on discussion in MOAD meeting) - use the code he has now to make a netcdf file of the HRDPS data with current naming convention (2015 onwards) and a sepratre netcdf for old naming convention (b4 2015) and then concatenate them in the PCA file. <br>\n",
    "Briefly went over how parrallel processing works with dask. Really helpful analogy with clerics counting the number of times a word is used in the bible. The number of clerics (and therefor the number of portions the bible is split into) is the number of processes going on, while the number of words that a cleric can keep track of at once is the number of threads each - this is a simple way of explaining how  computer can 'multitask' using dask. <br>\n",
    "&emsp; NOTE: salish has 16 cores (which looks like 32 when doing what you were (io memory stuff) because there are two threads for each core) so you cannot split your work between more than 32 clerics (less if there is any other work being done on Salish and 16 max if its being used mostly for computing).<br>\n",
    "\n",
    "Some new fun top tricks:<br>\n",
    "&emsp; u -> userID : to see userspecific processes <br>\n",
    "&emsp;&emsp; V : for tree of this users processes <br>\n",
    "&emsp; 1 : to see what all 32 cores are up to<br>\n",
    "&emsp;&emsp; us column = computing memory being used<br>\n",
    "&emsp;&emsp; sy = io memory being used<br>\n",
    "&emsp;&emsp; ni = priority (more posstive is low priority, more negative is high priority, set as 0 automatically)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuesday, January 5\n",
    "Ran and saved HRDPS netCDF files from Sep 2014 to present. Old file types are VERY funky. Some dates have time values from other dates, and the hourly time values within those dates are sometimes not in order. Seems to happen too often to be as simple as me fixing those dates (and still have time to do analysis for the presentation) so just going to do 2014 to present analysis. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wednesday, January 6\n",
    "Lots of progress on downscaling project. Formally moved on from doing downcalling with older HRDPS data. Completed PCA file and exported all the necessary PCA values, time, and lat and lon. <br>\n",
    "Began working on converting larger analysis over to using these exported numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
